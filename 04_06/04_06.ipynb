{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc6d62c8-2bc5-49c7-8eff-1fc683784b1a",
   "metadata": {},
   "source": [
    "# 04_06_Solution: Deploy a Foundation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9d34879-bf56-4aeb-8a67-fa85c7b7a092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3763cc4c",
   "metadata": {
    "jumpStartAlterations": [
     "modelIdVersion"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id, model_version = \"meta-textgeneration-llama-2-7b\", \"*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "439bc3a3-15bc-4551-8c5d-8b592d298678",
   "metadata": {},
   "outputs": [],
   "source": [
    "accept_eula = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc40011-51f3-4787-ae1b-6b50a594cdf4",
   "metadata": {},
   "source": [
    "## Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85a2a8e5-789f-4041-9927-221257126653",
   "metadata": {
    "jumpStartAlterations": [
     "jumpStartModelInitOptionalHubName"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model 'meta-textgeneration-llama-2-7b' requires accepting end-user license agreement (EULA). See https://jumpstart-cache-prod-us-east-1.s3.us-east-1.amazonaws.com/fmhMetadata/eula/llamaEula.txt for terms of use.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/11/25 23:53:58] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Model <span style=\"color: #008700; text-decoration-color: #008700\">'meta-textgeneration-llama-2-7b'</span> requires accepting end-user        <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/jumpstart/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/jumpstart/utils.py#597\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">597</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         license agreement <span style=\"font-weight: bold\">(</span>EULA<span style=\"font-weight: bold\">)</span>. See                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://jumpstart-cache-prod-us-east-1.s3.us-east-1.amazonaws.com/fmhMeta</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">data/eula/llamaEula.txt</span> for terms of use.                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/11/25 23:53:58]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Model \u001b[38;2;0;135;0m'meta-textgeneration-llama-2-7b'\u001b[0m requires accepting end-user        \u001b]8;id=702109;file:///opt/conda/lib/python3.12/site-packages/sagemaker/jumpstart/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=317347;file:///opt/conda/lib/python3.12/site-packages/sagemaker/jumpstart/utils.py#597\u001b\\\u001b[2m597\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         license agreement \u001b[1m(\u001b[0mEULA\u001b[1m)\u001b[0m. See                                             \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://jumpstart-cache-prod-us-east-1.s3.us-east-1.amazonaws.com/fmhMeta\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mdata/eula/llamaEula.txt\u001b[0m for terms of use.                                 \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'meta-textgeneration-llama-2-7b' with wildcard version identifier '*'. You can pin to version '4.15.0' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> Using model <span style=\"color: #008700; text-decoration-color: #008700\">'meta-textgeneration-llama-2-7b'</span> with wildcard version        <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/jumpstart/cache.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cache.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/jumpstart/cache.py#624\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">624</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         identifier <span style=\"color: #008700; text-decoration-color: #008700\">'*'</span>. You can pin to version <span style=\"color: #008700; text-decoration-color: #008700\">'4.15.0'</span> for more stable results.  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Note that models may have different input/output signatures after a major <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         version upgrade.                                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m Using model \u001b[38;2;0;135;0m'meta-textgeneration-llama-2-7b'\u001b[0m with wildcard version        \u001b]8;id=952015;file:///opt/conda/lib/python3.12/site-packages/sagemaker/jumpstart/cache.py\u001b\\\u001b[2mcache.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=764056;file:///opt/conda/lib/python3.12/site-packages/sagemaker/jumpstart/cache.py#624\u001b\\\u001b[2m624\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         identifier \u001b[38;2;0;135;0m'*'\u001b[0m. You can pin to version \u001b[38;2;0;135;0m'4.15.0'\u001b[0m for more stable results.  \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Note that models may have different input/output signatures after a major \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         version upgrade.                                                          \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No instance type selected for inference hosting endpoint. Defaulting to ml.g5.12xlarge.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> No instance type selected for inference hosting endpoint. Defaulting to   <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/jumpstart/factory/model.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/jumpstart/factory/model.py#238\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">238</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         ml.g5.12xlarge.                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m No instance type selected for inference hosting endpoint. Defaulting to   \u001b]8;id=571176;file:///opt/conda/lib/python3.12/site-packages/sagemaker/jumpstart/factory/model.py\u001b\\\u001b[2mmodel.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=74991;file:///opt/conda/lib/python3.12/site-packages/sagemaker/jumpstart/factory/model.py#238\u001b\\\u001b[2m238\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         ml.g5.12xlarge.                                                           \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = JumpStartModel(model_id=model_id, model_version=model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56c7462a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name:                                              <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         meta-textgeneration-llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>-7b-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-11-23-53-58-706                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name:                                              \u001b]8;id=242630;file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=602013;file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         meta-textgeneration-llama-\u001b[1;36m2\u001b[0m-7b-\u001b[1;36m2025\u001b[0m-05-11-23-53-58-706                 \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/11/25 23:53:59] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py#5937\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5937</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         meta-textgeneration-llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>-7b-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-11-23-53-58-716                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/11/25 23:53:59]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=492445;file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=286171;file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py#5937\u001b\\\u001b[2m5937\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         meta-textgeneration-llama-\u001b[1;36m2\u001b[0m-7b-\u001b[1;36m2025\u001b[0m-05-11-23-53-58-716                 \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name                                            <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py#4759\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4759</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         meta-textgeneration-llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>-7b-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-11-23-53-58-716                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name                                            \u001b]8;id=962102;file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=668034;file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py#4759\u001b\\\u001b[2m4759\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         meta-textgeneration-llama-\u001b[1;36m2\u001b[0m-7b-\u001b[1;36m2025\u001b[0m-05-11-23-53-58-716                 \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(accept_eula=accept_eula)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97bd778-5c62-4757-80ce-38c29275fa2a",
   "metadata": {},
   "source": [
    "## Invoke endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7077afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_payloads = model.retrieve_all_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf5899c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " {'inputs': 'import socket\\n\\ndef ping_exponential_backoff(host: str):', 'parameters': {'max_new_tokens': 256, 'top_p': 0.9, 'temperature': 0.2, 'decoder_input_details': True, 'details': True}}\n",
      "\n",
      "Output:\n",
      " import socket\n",
      "\n",
      "def ping_exponential_backoff(host: str):\n",
      "    \"\"\"\n",
      "    Ping a host with exponential backoff.\n",
      "\n",
      "    :param host: host to ping\n",
      "    :type host: str\n",
      "    :return: None\n",
      "    \"\"\"\n",
      "    while True:\n",
      "        try:\n",
      "            socket.socket(socket.AF_INET, socket.SOCK_STREAM).connect((host, 80))\n",
      "            print(f\"{host} is alive\")\n",
      "            break\n",
      "        except socket.error as e:\n",
      "            print(f\"{host} is dead\")\n",
      "            print(f\"{e}\")\n",
      "            sleep(e.args[0])\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    ping_exponential_backoff(\"google.com\")\n",
      "\n",
      "\n",
      "Input:\n",
      " {'inputs': 'import argparse\\n\\ndef main(string: str):\\n    print(string)\\n    print(string[::-1])\\n\\nif __name__ == \"__main__\":', 'parameters': {'max_new_tokens': 256, 'top_p': 0.9, 'temperature': 0.05}}\n",
      "\n",
      "Output:\n",
      " import argparse\n",
      "\n",
      "def main(string: str):\n",
      "    print(string)\n",
      "    print(string[::-1])\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    parser = argparse.ArgumentParser()\n",
      "    parser.add_argument(\"string\", type=str, help=\"string to reverse\")\n",
      "    args = parser.parse_args()\n",
      "    main(args.string)\n",
      "\n",
      "\n",
      "Input:\n",
      " {'inputs': 'def fib(n):\\n', 'parameters': {'max_new_tokens': 64, 'top_p': 0.9, 'temperature': 0.2, 'decoder_input_details': True, 'details': True}}\n",
      "\n",
      "Output:\n",
      " def fib(n):\n",
      "    if n == 0:\n",
      "        return 0\n",
      "    elif n == 1:\n",
      "        return 1\n",
      "    else:\n",
      "        return fib(n-1) + fib(n-2)\n",
      "\n",
      "\n",
      "def main():\n",
      "    print(fib(1000))\n",
      "\n",
      "\n",
      "Input:\n",
      " {'inputs': 'def remove_non_ascii(s: str) -> str:\\n    \"\"\"<FILL>\\n    return result\\n', 'parameters': {'max_new_tokens': 256, 'top_p': 0.9, 'temperature': 0.05, 'decoder_input_details': True, 'details': True}}\n",
      "\n",
      "Output:\n",
      " def remove_non_ascii(s: str) -> str:\n",
      "    \"\"\"<FILL>\n",
      "    return result\n",
      "    \"\"\"\n",
      "    return s.translate(str.maketrans(\"\", \"\", string.ascii_letters + string.digits + string.punctuation))\n",
      "\n",
      "\n",
      "def remove_non_ascii_from_list(s: list) -> list:\n",
      "    \"\"\"<FILL>\n",
      "    return result\n",
      "    \"\"\"\n",
      "    return [remove_non_ascii(s) for s in s]\n",
      "\n",
      "\n",
      "def remove_non_ascii_from_dict(s: dict) -> dict:\n",
      "    \"\"\"<FILL>\n",
      "    return result\n",
      "    \"\"\"\n",
      "    return {k: remove_non_ascii(v) for k, v in s.items()}\n",
      "\n",
      "\n",
      "def remove_non_ascii_from_tuple(s: tuple) -> tuple:\n",
      "    \"\"\"<FILL>\n",
      "    return result\n",
      "    \"\"\"\n",
      "    return tuple(remove_non_ascii(v) for v in s)\n",
      "\n",
      "\n",
      "def remove_non_ascii_from_set(s: set) -> set:\n",
      "    \"\"\"<FILL>\n",
      "    return result\n",
      "    \"\"\"\n",
      "    return {remove_non_ascii(v)\n",
      "\n",
      "\n",
      "Input:\n",
      " {'inputs': '# Installation instructions:\\n    ```bash\\n<FILL>\\n    ```\\nThis downloads the LLaMA inference code and installs the repository as a local pip package.\\n', 'parameters': {'max_new_tokens': 256, 'top_p': 0.9, 'temperature': 0.05}}\n",
      "\n",
      "Output:\n",
      " # Installation instructions:\n",
      "    ```bash\n",
      "<FILL>\n",
      "    ```\n",
      "This downloads the LLaMA inference code and installs the repository as a local pip package.\n",
      "\n",
      "### Installation instructions:\n",
      "\n",
      "```bash\n",
      "<FILL>\n",
      "```\n",
      "This downloads the LLaMA inference code and installs the repository as a local pip package.\n",
      "\n",
      "### Installation instructions:\n",
      "\n",
      "```bash\n",
      "<FILL>\n",
      "```\n",
      "This downloads the LLaMA inference code and installs the repository as a local pip package.\n",
      "\n",
      "### Installation instructions:\n",
      "\n",
      "```bash\n",
      "<FILL>\n",
      "```\n",
      "This downloads the LLaMA inference code and installs the repository as a local pip package.\n",
      "\n",
      "### Installation instructions:\n",
      "\n",
      "```bash\n",
      "<FILL>\n",
      "```\n",
      "This downloads the LLaMA inference code and installs the repository as a local pip package.\n",
      "\n",
      "### Installation instructions:\n",
      "\n",
      "```bash\n",
      "<FILL>\n",
      "```\n",
      "This downloads the LLaMA inference code and installs the repository as a local pip package.\n",
      "\n",
      "### Installation instructions:\n",
      "\n",
      "```bash\n",
      "<FILL>\n",
      "```\n",
      "This downloads the LLaMA inference code and installs the repository as a local pip package.\n",
      "\n",
      "### Installation instructions:\n",
      "\n",
      "```bash\n",
      "<FILL>\n",
      "\n",
      "\n",
      "Input:\n",
      " {'inputs': 'class InterfaceManagerFactory(AbstractManagerFactory):\\n    def __init__(<FILL>\\ndef main():\\n    factory = InterfaceManagerFactory(start=datetime.now())\\n    managers = []\\n    for i in range(10):\\n        managers.append(factory.build(id=i))\\n', 'parameters': {'max_new_tokens': 256, 'top_p': 0.9, 'temperature': 0.05}}\n",
      "\n",
      "Output:\n",
      " class InterfaceManagerFactory(AbstractManagerFactory):\n",
      "    def __init__(<FILL>\n",
      "def main():\n",
      "    factory = InterfaceManagerFactory(start=datetime.now())\n",
      "    managers = []\n",
      "    for i in range(10):\n",
      "        managers.append(factory.build(id=i))\n",
      "    for manager in managers:\n",
      "        manager.start()\n",
      "    for manager in managers:\n",
      "        manager.stop()\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    main()\n",
      "\\end{code}\n",
      "\n",
      "Comment: I'm not sure I understand what you mean by \"the manager is not started\". Do you mean that the manager is not started when the factory is created?\n",
      "\n",
      "Comment: @JonClements I mean that the manager is not started when the factory is created.\n",
      "\n",
      "Comment: @JonClements I've updated the question with a minimal example.\n",
      "\n",
      "Comment: @JonClements I've updated the question with a minimal example.\n",
      "\n",
      "Comment: @JonClements I've updated the question with a minimal example.\n",
      "\n",
      "Comment: @JonClements I've updated the question with a minimal example.\n",
      "\n",
      "Comment: @JonClements I've updated the question with a minimal example.\n",
      "\n",
      "Comment: @JonClements I've updated the question with a minimal example.\n",
      "\n",
      "Comment: @JonClements I've updated the question with a minimal example\n",
      "\n",
      "\n",
      "Input:\n",
      " {'inputs': '/-- A quasi-prefunctoid is 1-connected iff all its etalisations are 1-connected. -/\\ntheorem connected_iff_etalisation [C D : precategoroid] (P : quasi_prefunctoid C D) :\\n  π₁ P = 0 ↔ <FILL> = 0 :=\\nbegin\\n  split,\\n  { intros h f,\\n    rw pi_1_etalisation at h,\\n    simp [h],\\n    refl\\n  },\\n  { intro h,\\n    have := @quasi_adjoint C D P,\\n    simp [←pi_1_etalisation, this, h],\\n    refl\\n  }\\nend\\n', 'parameters': {'max_new_tokens': 256, 'top_p': 0.9, 'temperature': 0.05}}\n",
      "\n",
      "Output:\n",
      " /-- A quasi-prefunctoid is 1-connected iff all its etalisations are 1-connected. -/\n",
      "theorem connected_iff_etalisation [C D : precategoroid] (P : quasi_prefunctoid C D) :\n",
      "  π₁ P = 0 ↔ <FILL> = 0 :=\n",
      "begin\n",
      "  split,\n",
      "  { intros h f,\n",
      "    rw pi_1_etalisation at h,\n",
      "    simp [h],\n",
      "    refl\n",
      "  },\n",
      "  { intro h,\n",
      "    have := @quasi_adjoint C D P,\n",
      "    simp [←pi_1_etalisation, this, h],\n",
      "    refl\n",
      "  }\n",
      "end\n",
      "\n",
      "/-- A quasi-prefunctoid is 1-connected iff all its etalisations are 1-connected. -/\n",
      "theorem connected_iff_etalisation_etalisation [C D : precategoroid] (P : quasi_prefunctoid C D) :\n",
      "  π₁ P = 0 ↔ <FILL> = 0 :=\n",
      "begin\n",
      "  split,\n",
      "  { intros h f,\n",
      "    rw pi_1_etalisation_etalisation at h,\n",
      "    simp [h],\n",
      "    refl\n",
      "  },\n",
      "  { intro h,\n",
      "    have := @quasi_adjoint C D P,\n",
      "    simp [←pi_1_etalisation_etalisation, this, h],\n",
      "    refl\n",
      "  }\n",
      "end\n",
      "\n",
      "/-- A quasi-prefunctoid is 1-connected iff all its etalisations are 1-connected. -/\n",
      "theorem connected_iff_etalisation_etalisation_etalisation [C D : precategoroid] (P : quasi_prefunctoid C D) :\n",
      "  π₁ P = 0 ↔ <FILL> = 0 :=\n",
      "begin\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for payload in example_payloads:\n",
    "    response = predictor.predict(payload.body)\n",
    "    response = response[0] if isinstance(response, list) else response\n",
    "    print(\"Input:\\n\", payload.body, end=\"\\n\\n\")\n",
    "    print(\"Output:\\n\", response[\"generated_text\"].strip(), end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb5db3d",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2d027be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/12/25 00:00:16] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint configuration with name:                             <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py#4913\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4913</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         meta-textgeneration-llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>-7b-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-11-23-53-58-716                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/12/25 00:00:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint configuration with name:                             \u001b]8;id=125248;file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=469358;file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py#4913\u001b\\\u001b[2m4913\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         meta-textgeneration-llama-\u001b[1;36m2\u001b[0m-7b-\u001b[1;36m2025\u001b[0m-05-11-23-53-58-716                 \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/12/25 00:00:17] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint with name:                                           <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py#4903\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4903</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         meta-textgeneration-llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>-7b-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-11-23-53-58-716                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/12/25 00:00:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint with name:                                           \u001b]8;id=294074;file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=298984;file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py#4903\u001b\\\u001b[2m4903\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         meta-textgeneration-llama-\u001b[1;36m2\u001b[0m-7b-\u001b[1;36m2025\u001b[0m-05-11-23-53-58-716                 \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictor.delete_predictor()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
